{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Aditya\\\\Documents\\\\Aditya\\\\Hackathons\\\\init_prep\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Aditya\\\\Documents\\\\Aditya\\\\Hackathons\\\\init_prep'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_test_size: float\n",
    "    params_random_state: int\n",
    "    params_probability: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heartDiseaseClassification.constants import *\n",
    "from heartDiseaseClassification.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        create_directories([config.root_dir])\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            params_test_size=self.params.TEST_SIZE,\n",
    "            params_random_state=self.params.RANDOM_STATE,\n",
    "            params_probability=self.params.PROBABILITY\n",
    "        )\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_18328\\1018924555.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-06 02:30:09,113: WARNING: module_wrapper: From c:\\Users\\Aditya\\Documents\\Aditya\\Hackathons\\init_prep\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareBaseModelConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        logistic_regression = LogisticRegression(random_state=self.config.params_random_state)\n",
    "        random_forest = RandomForestClassifier(random_state=self.config.params_random_state)\n",
    "        decision_tree = DecisionTreeClassifier(random_state=self.config.params_random_state)\n",
    "        svc = SVC(probability=self.config.params_probability, random_state=self.config.params_random_state)\n",
    "\n",
    "        self.model = VotingClassifier(estimators=[('lr', logistic_regression), ('rf', random_forest), ('dt', decision_tree), ('svc', svc)], voting='soft')\n",
    "\n",
    "        self.save_model(path=self.config.base_model_path, model=self.model)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, X_train_scaled, y_train):\n",
    "        full_model = model.fit(X_train_scaled, y_train)\n",
    "        # y_pred = full_model.predict(X_train_scaled)\n",
    "        # print(\"Classification Report:\\n\", classification_report(y_train, y_pred))\n",
    "        return full_model\n",
    "    \n",
    "    def update_base_model(self):\n",
    "        filePath = f\"{self.config.root_dir.parent}/data_ingestion/my_data.csv\"\n",
    "        data = pd.read_csv(filePath)\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        df_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "        X = df_imputed.drop('target', axis=1)\n",
    "        y = df_imputed['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "        y_test = pd.DataFrame(y_test, columns=['target'])\n",
    "        y_train = pd.DataFrame(y_train, columns=['target'])\n",
    "        X_train_scaled.to_csv(\n",
    "            f\"{self.config.root_dir.parent}/data_ingestion/X_train_scaled.csv\", index=False)\n",
    "        X_test_scaled.to_csv(\n",
    "            f\"{self.config.root_dir.parent}/data_ingestion/X_test_scaled.csv\", index=False)\n",
    "        y_train.to_csv(\n",
    "            f\"{self.config.root_dir.parent}/data_ingestion/y_train.csv\", index=False)\n",
    "        y_test.to_csv(\n",
    "            f\"{self.config.root_dir.parent}/data_ingestion/y_test.csv\", index=False)\n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model = self.model,\n",
    "            X_train_scaled = X_train_scaled,\n",
    "            y_train = y_train\n",
    "        )\n",
    "        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        try:\n",
    "            joblib.dump(model, path)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error in saving model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-06 02:30:09,438: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-02-06 02:30:09,441: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-06 02:30:09,443: INFO: common: created directory at: artifacts]\n",
      "[2024-02-06 02:30:09,444: INFO: common: created directory at: artifacts/prepare_base_model]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\Documents\\Aditya\\Hackathons\\init_prep\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Aditya\\Documents\\Aditya\\Hackathons\\init_prep\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
